{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "INFO5731_Assignment_Two.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rushithakondreddy/haihua_INFO5731_Spring2020/blob/main/INFO5731_Assignment_Two.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USSdXHuqnwv9"
      },
      "source": [
        "# **INFO5731 Assignment Two**\n",
        "\n",
        "In this assignment, you will try to gather text data from open data source via web scraping or API. After that you need to clean the text data and syntactic analysis of the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWxodXh5n4xF"
      },
      "source": [
        "# **Question 1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TenBkDJ5n95k"
      },
      "source": [
        "(40 points). Write a python program to collect text data from **either of the following sources** and save the data into a **csv file**:\n",
        "\n",
        "(1) Collect all the customer reviews of the product [2019 Dell labtop](https://www.amazon.com/Dell-Inspiron-5000-5570-Laptop/dp/B07N49F51N/ref=sr_1_11?crid=1IJ7UWF2F4GHH&keywords=dell%2Bxps%2B15&qid=1580173569&sprefix=dell%2Caps%2C181&sr=8-11&th=1) on amazon.\n",
        "\n",
        "(2) Collect the top 100 User Reviews of the film [Joker](https://www.imdb.com/title/tt7286456/reviews?ref_=tt_urv) from IMDB.\n",
        "\n",
        "(3) Collect the abstracts of the top 100 research papers by using the query [natural language processing](https://citeseerx.ist.psu.edu/search?q=natural+language+processing&submit.x=0&submit.y=0&sort=rlv&t=doc) from CiteSeerX.\n",
        "\n",
        "(4) Collect the top 100 tweets by using hashtag [\"#CovidVaccine\"](https://twitter.com/hashtag/CovidVaccine) from Twitter. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "PuFPKhC0m1fd",
        "outputId": "87512563-83e5-4cde-fa40-3649511b31c6"
      },
      "source": [
        "# Write your code here\n",
        "\n",
        "import requests\n",
        "from urllib.parse import urljoin\n",
        "from bs4 import BeautifulSoup as BS\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def get_tablelist(soup):\n",
        "    reviews = soup.find_all(\"div\", {\"class\": \"lister-item-content\"})\n",
        "\n",
        "    review_data = []\n",
        "\n",
        "    for review in reviews:\n",
        "\n",
        "        try:\n",
        "            review_content = review.find(\"div\", {\"class\": \"text show-more__control\"}).text.strip()\n",
        "        except:\n",
        "            review_content = review.find(\"div\", {\"class\": \"text show-more__control clickable\"}).text.strip()\n",
        "\n",
        "        review_data.append(review_content)\n",
        "    return review_data\n",
        "\n",
        "b_url = 'https://www.imdb.com/'\n",
        "url = 'https://www.imdb.com/title/tt7286456/reviews?ref_=tt_urv'\n",
        "res = requests.get(url)\n",
        "soup = BS(res.text, 'html.parser')\n",
        "res.encoding = 'utf-8'\n",
        "allTablelist=[]\n",
        "tablelist = get_tablelist(soup)\n",
        "for i in tablelist:\n",
        "  allTablelist.append(i)\n",
        "\n",
        "load_more = soup.select(\".load-more-data\")\n",
        "flag = True\n",
        "if len(load_more):\n",
        "    ajaxurl = load_more[0]['data-ajaxurl']\n",
        "    b_url = b_url + ajaxurl + \"?ref_=undefined&paginationKey=\"\n",
        "    try:\n",
        "        key = load_more[0]['data-key']\n",
        "    except KeyError:\n",
        "        flag = False\n",
        "else:\n",
        "    flag = False\n",
        "\n",
        "while flag:\n",
        "    url = b_url + key\n",
        "    res = requests.get(url)\n",
        "    res.encoding = 'utf-8'\n",
        "    soup = BS(res.text, 'html.parser')\n",
        "    tablelist2 = get_tablelist(soup)\n",
        "    if len(allTablelist) == 100:\n",
        "      break\n",
        "    for i in tablelist2:\n",
        "        allTablelist.append(i)\n",
        "    load_more = soup.select(\".load-more-data\")\n",
        "    if len(load_more):\n",
        "        key = load_more[0]['data-key']\n",
        "    else:\n",
        "        flag = False\n",
        "\n",
        "data = np.array(allTablelist)\n",
        "data = pd.DataFrame(data, columns=['review_content'])\n",
        "data.shape\n",
        "data.to_csv('review_data.csv')\n",
        "data\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Every once in a while a movie comes, that trul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This is a movie that only those who have felt ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Truly a masterpiece, The Best Hollywood film o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Joaquin Phoenix gives a tour de force performa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Most of the time movies are anticipated like t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>This film tries desperately to devillify the m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>Wow I honestly gotta tell you, it's one of the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>The whole point of this movie is to bring atte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>While I enjoyed the film, it felt pretty short...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>There is doing an homage and then there is bor...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       review_content\n",
              "0   Every once in a while a movie comes, that trul...\n",
              "1   This is a movie that only those who have felt ...\n",
              "2   Truly a masterpiece, The Best Hollywood film o...\n",
              "3   Joaquin Phoenix gives a tour de force performa...\n",
              "4   Most of the time movies are anticipated like t...\n",
              "..                                                ...\n",
              "95  This film tries desperately to devillify the m...\n",
              "96  Wow I honestly gotta tell you, it's one of the...\n",
              "97  The whole point of this movie is to bring atte...\n",
              "98  While I enjoyed the film, it felt pretty short...\n",
              "99  There is doing an homage and then there is bor...\n",
              "\n",
              "[100 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfpMRCrRwN6Z"
      },
      "source": [
        "# **Question 2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dCQEbDawWCw"
      },
      "source": [
        "(30 points). Write a python program to **clean the text data** you collected above and save the data in a new column in the csv file. The data cleaning steps include:\n",
        "\n",
        "(1) Remove noise, such as special characters and punctuations.\n",
        "\n",
        "(2) Remove numbers.\n",
        "\n",
        "(3) Remove stopwords by using the [stopwords list](https://gist.github.com/sebleier/554280).\n",
        "\n",
        "(4) Lowercase all texts\n",
        "\n",
        "(5) Stemming. \n",
        "\n",
        "(6) Lemmatization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vATjQNTY8buA",
        "outputId": "9d995ce4-1c65-4253-eecb-4a324ba76030"
      },
      "source": [
        "#converting to lowercase\n",
        "\n",
        "data['review_content'] = data['review_content'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
        "data['review_content'].head()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    every once in a while a movie comes, that trul...\n",
              "1    this is a movie that only those who have felt ...\n",
              "2    truly a masterpiece, the best hollywood film o...\n",
              "3    joaquin phoenix gives a tour de force performa...\n",
              "4    most of the time movies are anticipated like t...\n",
              "Name: review_content, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCLXbiPuhwuM",
        "outputId": "f3a08bf7-227f-46e0-d507-a85672cf27d9"
      },
      "source": [
        "#remove punct\n",
        "data['review_content'] = data['review_content'].str.replace('[^\\w\\s]','')\n",
        "data['review_content'].head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    every once in a while a movie comes that truly...\n",
              "1    this is a movie that only those who have felt ...\n",
              "2    truly a masterpiece the best hollywood film of...\n",
              "3    joaquin phoenix gives a tour de force performa...\n",
              "4    most of the time movies are anticipated like t...\n",
              "Name: review_content, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QashtSPehwxc",
        "outputId": "35e86d7e-4963-45ef-c0f7-1256e98a1b29"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MefUoyNhw0p",
        "outputId": "d670e192-3f09-4822-d572-69e3e1403132"
      },
      "source": [
        "# remove stopwords\n",
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')\n",
        "data['review_content'] = data['review_content'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
        "data['review_content'].head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    every movie comes truly makes impact joaquins ...\n",
              "1    movie felt alone isolated truly relate underst...\n",
              "2    truly masterpiece best hollywood film 2019 one...\n",
              "3    joaquin phoenix gives tour de force performanc...\n",
              "4    time movies anticipated like end falling short...\n",
              "Name: review_content, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjD4Ext5iPfh",
        "outputId": "7f9b29ff-0459-42d3-e93b-2ad9fc0492b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#remove special characters\n",
        "import string\n",
        "string.punctuation\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjUqY4dliPnH",
        "outputId": "eb3211b8-50e9-4db3-a0c3-6b2debf330d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "#remove special characters\n",
        "data['review_content'] = data['review_content'].apply(lambda x: \" \".join(x.strip(string.punctuation) for x in x.split()))  \n",
        "data['review_content']"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     every movie comes truly makes impact joaquins ...\n",
              "1     movie felt alone isolated truly relate underst...\n",
              "2     truly masterpiece best hollywood film 2019 one...\n",
              "3     joaquin phoenix gives tour de force performanc...\n",
              "4     time movies anticipated like end falling short...\n",
              "                            ...                        \n",
              "95    film tries desperately devillify stylish chari...\n",
              "96    wow honestly gotta tell one best movies ive se...\n",
              "97    whole point movie bring attention mental illne...\n",
              "98    enjoyed film felt pretty short end appeared sc...\n",
              "99    homage borrowing wholesale material film littl...\n",
              "Name: review_content, Length: 100, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWR_c86riWaU",
        "outputId": "4ff90e20-5247-43ff-cca2-95e83f0cfa82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#remove numbers\n",
        "data['review_content'] = data['review_content'].apply(lambda x: \" \".join(x for x in x.split() if not x.isdigit()))\n",
        "data['review_content']"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     every movie comes truly makes impact joaquins ...\n",
              "1     movie felt alone isolated truly relate underst...\n",
              "2     truly masterpiece best hollywood film one best...\n",
              "3     joaquin phoenix gives tour de force performanc...\n",
              "4     time movies anticipated like end falling short...\n",
              "                            ...                        \n",
              "95    film tries desperately devillify stylish chari...\n",
              "96    wow honestly gotta tell one best movies ive se...\n",
              "97    whole point movie bring attention mental illne...\n",
              "98    enjoyed film felt pretty short end appeared sc...\n",
              "99    homage borrowing wholesale material film littl...\n",
              "Name: review_content, Length: 100, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XI0fbt9iWgT",
        "outputId": "67b65c73-2918-4afe-b983-3f624ecf6aea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#spell correction\n",
        "from textblob import TextBlob\n",
        "data['review_content'][:5].apply(lambda x: str(TextBlob(x).correct()))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    every movie comes truly makes impact joaquins ...\n",
              "1    movie felt alone isolated truly relate underst...\n",
              "2    truly masterpiece best hollywood film one best...\n",
              "3    joaquin phoenix gives tour de force performanc...\n",
              "4    time moves anticipated like end falling short ...\n",
              "Name: review_content, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiunp-Isiby4",
        "outputId": "8519a148-407f-460e-99cf-6cac8817d3cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#stemming\n",
        "from nltk.stem import PorterStemmer\n",
        "st = PorterStemmer()\n",
        "data['review_content'][:5].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    everi movi come truli make impact joaquin perf...\n",
              "1    movi felt alon isol truli relat understand mot...\n",
              "2    truli masterpiec best hollywood film one best ...\n",
              "3    joaquin phoenix give tour de forc perform fear...\n",
              "4    time movi anticip like end fall short way shor...\n",
              "Name: review_content, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sb4BLjypikCA",
        "outputId": "537be1c9-8dda-4a77-fcc0-1b9e272e0fbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#lemmatization\n",
        "from textblob import Word\n",
        "nltk.download('wordnet')\n",
        "data['review_content'] = data['review_content'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
        "data['review_content'].head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    every movie come truly make impact joaquins pe...\n",
              "1    movie felt alone isolated truly relate underst...\n",
              "2    truly masterpiece best hollywood film one best...\n",
              "3    joaquin phoenix give tour de force performance...\n",
              "4    time movie anticipated like end falling short ...\n",
              "Name: review_content, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5mmYIfN8eYV"
      },
      "source": [
        "# **Question 3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsi2y4z88ngX"
      },
      "source": [
        "(30 points). Write a python program to conduct **syntax and structure analysis** of the clean text you just saved above. The syntax and structure analysis includes: \n",
        "\n",
        "(1) Parts of Speech (POS) Tagging: Tag Parts of Speech of each word in the text, and calculate the total number of N(oun), V(erb), Adj(ective), Adv(erb), respectively.\n",
        "\n",
        "(2) Constituency Parsing and Dependency Parsing: print out the constituency parsing trees and dependency parsing trees of all the sentences. Using one sentence as an example to explain your understanding about the constituency parsing tree and dependency parsing tree.\n",
        "\n",
        "(3) Named Entity Recognition: Extract all the entities such as person names, organizations, locations, product names, and date from the clean texts, calculate the count of each entity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQKnPjPDHJHr",
        "outputId": "3338db1c-86f0-456f-9164-8802154e0ae0"
      },
      "source": [
        "# Write your code here\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hy5CNEBpiqtD",
        "outputId": "6c405ef4-06c4-4c22-a84c-749750c8415a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aprgTAo_iq1c",
        "outputId": "98ac585d-29a9-41aa-855f-4ed365beb767",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk import word_tokenize, pos_tag, pos_tag_sents\n",
        "data['POSTags'] =  pos_tag_sents( data['review_content'].apply(word_tokenize).tolist() )\n",
        "print(data)\n",
        "\n",
        "pos = data['POSTags'].to_list()\n",
        "pos\n",
        "nouns = 0\n",
        "for x in pos:\n",
        "  for a,b in x:\n",
        "    if(b.startswith('N')):\n",
        "       nouns+=1\n",
        "res = \"nouns:{}\".format(nouns)\n",
        "print(res)\n",
        "verb = 0\n",
        "for x in pos:\n",
        "  for a,b in x:\n",
        "    if(b.startswith('V')):\n",
        "       verb+=1\n",
        "res1 = \"verb:{}\".format(verb)\n",
        "print(res1)\n",
        "adverb = 0\n",
        "for x in pos:\n",
        "  for a,b in x:\n",
        "    if(b.startswith('R')):\n",
        "       adverb+=1\n",
        "res2 = \"adverb:{}\".format(adverb)\n",
        "print(res2)\n",
        "adj = 0\n",
        "for x in pos:\n",
        "  for a,b in x:\n",
        "    if(b.startswith('J')):\n",
        "       adj+=1\n",
        "res3 = \"adj:{}\".format(adj)\n",
        "print(res3)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                       review_content                                            POSTags\n",
            "0   every movie come truly make impact joaquins pe...  [(every, DT), (movie, NN), (come, VBN), (truly...\n",
            "1   movie felt alone isolated truly relate underst...  [(movie, NN), (felt, VBD), (alone, RB), (isola...\n",
            "2   truly masterpiece best hollywood film one best...  [(truly, RB), (masterpiece, JJ), (best, JJS), ...\n",
            "3   joaquin phoenix give tour de force performance...  [(joaquin, NN), (phoenix, NN), (give, VB), (to...\n",
            "4   time movie anticipated like end falling short ...  [(time, NN), (movie, NN), (anticipated, VBN), ...\n",
            "..                                                ...                                                ...\n",
            "95  film try desperately devillify stylish charism...  [(film, NN), (try, VB), (desperately, RB), (de...\n",
            "96  wow honestly gotta tell one best movie ive see...  [(wow, NN), (honestly, RB), (got, VBD), (ta, R...\n",
            "97  whole point movie bring attention mental illne...  [(whole, JJ), (point, NN), (movie, NN), (bring...\n",
            "98  enjoyed film felt pretty short end appeared sc...  [(enjoyed, VBN), (film, NN), (felt, VBD), (pre...\n",
            "99  homage borrowing wholesale material film littl...  [(homage, NN), (borrowing, VBG), (wholesale, J...\n",
            "\n",
            "[100 rows x 2 columns]\n",
            "nouns:3672\n",
            "verb:1577\n",
            "adverb:757\n",
            "adj:1726\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8MKXRYZiq8i",
        "outputId": "3b97d3b3-2fa4-40b2-ccd0-827a8a17dbf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#entity recognition\n",
        "!pip install spacy"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (53.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (3.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ihrn8plEi02k",
        "outputId": "a7fd84d2-0a8e-493e-fb56-af40b5d50e27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "from collections import Counter\n",
        "import en_core_web_sm\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "data['review_content']\n",
        "list = data['review_content'].tolist()\n",
        "list[0]\n",
        "for x in list:\n",
        "   doc = (nlp(x))\n",
        "   print([(X.text, X.label_) for X in doc.ents])\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n",
            "[('one', 'CARDINAL')]\n",
            "[('hollywood', 'GPE'), ('one', 'CARDINAL')]\n",
            "[('joaquin phoenix', 'PERSON'), ('de force', 'ORG'), ('portrayal', 'NORP')]\n",
            "[('dark joker', 'ORG'), ('villain', 'GPE')]\n",
            "[('joaquin phoneix', 'PERSON')]\n",
            "[('arthur madness', 'PERSON'), ('phillips', 'PERSON')]\n",
            "[('yesterday', 'DATE'), ('venice', 'GPE'), ('itjoker', 'PERSON'), ('venice', 'GPE'), ('nolans', 'NORP'), ('scorsese', 'NORP'), ('hollywood', 'GPE')]\n",
            "[('joaquin', 'PERSON'), ('niro joaquin', 'PERSON')]\n",
            "[('joker venice', 'PERSON'), ('joaquin', 'PERSON'), ('robert', 'PERSON')]\n",
            "[('phoenix superb', 'ORG'), ('arthur mental state deep psychological', 'ORG'), ('one', 'CARDINAL'), ('three', 'CARDINAL')]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[('joaquin phoenix', 'PERSON'), ('todd phillips', 'PERSON'), ('disturbed', 'ORG')]\n",
            "[('joaquin phoenix', 'PERSON')]\n",
            "[('year ago', 'DATE'), ('joaquin phoenix', 'PERSON'), ('jack nicholson', 'PERSON')]\n",
            "[]\n",
            "[('joaquin phoenix joker', 'PERSON'), ('joker jack nicholsons', 'PERSON'), ('phoenix', 'GPE'), ('one', 'CARDINAL')]\n",
            "[('ten', 'CARDINAL'), ('drama thriller', 'PERSON')]\n",
            "[('phoenix outstandingso', 'ORG'), ('kinda justeh', 'PERSON')]\n",
            "[('year', 'DATE'), ('10', 'CARDINAL'), ('phoenix', 'GPE'), ('emptyfilm year', 'EVENT')]\n",
            "[]\n",
            "[('one', 'CARDINAL'), ('groupi', 'PERSON'), ('first', 'ORDINAL'), ('last decade', 'DATE'), ('joaquin phoenix', 'PERSON'), ('thingjoker', 'PERSON')]\n",
            "[('hour', 'TIME'), ('standup', 'PERSON'), ('mehe', 'ORG'), ('homocideit', 'GPE')]\n",
            "[('joaquin phoenix', 'PERSON'), ('oscar joaquin', 'PERSON'), ('one', 'CARDINAL'), ('one', 'CARDINAL'), ('todd philip', 'PERSON'), ('one', 'CARDINAL'), ('joaquin phoenix joker', 'PERSON'), ('jack heath', 'PERSON')]\n",
            "[('half', 'CARDINAL'), ('lifethere', 'GPE')]\n",
            "[('phoenix', 'GPE'), ('phoenix movieas', 'PERSON'), ('recent year', 'DATE'), ('one', 'CARDINAL'), ('wayne', 'PERSON')]\n",
            "[('phoenix show u joker', 'ORG'), ('u power', 'ORG'), ('philip hand perfect choice music camera angle lighting', 'ORG'), ('today', 'DATE'), ('first', 'ORDINAL')]\n",
            "[('arthur fleck', 'PERSON'), ('thomas wayne', 'PERSON'), ('s', 'ORG')]\n",
            "[('joaquin phoenix', 'PERSON'), ('todd phillips', 'PERSON'), ('superb', 'PERSON')]\n",
            "[('phoenix', 'GPE'), ('couple hour', 'TIME'), ('second', 'ORDINAL'), ('one', 'CARDINAL')]\n",
            "[('champion movie joker life', 'ORG')]\n",
            "[]\n",
            "[('arthur fleck life invalid', 'ORG'), ('weekly', 'DATE'), ('robert de niro', 'PERSON'), ('fantasy', 'GPE'), ('first', 'ORDINAL')]\n",
            "[('two', 'CARDINAL'), ('1best', 'CARDINAL'), ('3original', 'CARDINAL'), ('hollywood', 'GPE')]\n",
            "[]\n",
            "[('night', 'TIME'), ('august', 'DATE'), ('venice international film festival', 'ORG'), ('joaquin phoenix', 'ORG'), ('arthur', 'PERSON'), ('phoenix', 'PERSON'), ('joaquin phoenix', 'PERSON'), ('1970s', 'DATE'), ('gotham city', 'GPE'), ('two', 'CARDINAL'), ('martin', 'ORG'), ('scorsese', 'NORP'), ('standup comedy king comedy', 'PERSON'), ('standup comedian', 'PERSON'), ('house', 'ORG'), ('arthur', 'PERSON'), ('second', 'ORDINAL'), ('wayne', 'PERSON'), ('half', 'CARDINAL'), ('murray franklin', 'PERSON'), ('phoenix', 'GPE'), ('robert de niros', 'PERSON')]\n",
            "[('thomas wayne', 'PERSON'), ('europe', 'LOC'), ('north america', 'LOC')]\n",
            "[('joaquin portrayal', 'PERSON'), ('joaquin phoenix', 'PERSON'), ('cgi super power great villain', 'ORG')]\n",
            "[('one', 'CARDINAL'), ('one', 'CARDINAL')]\n",
            "[('joaquin phoenix', 'PERSON'), ('one', 'CARDINAL')]\n",
            "[('hour', 'TIME'), ('hour', 'TIME')]\n",
            "[('first', 'ORDINAL')]\n",
            "[('couple week', 'DATE'), ('joaquin phoenix', 'PERSON')]\n",
            "[('arthur', 'ORG'), ('first', 'ORDINAL'), ('arthur', 'PERSON'), ('one', 'CARDINAL'), ('last decade', 'DATE'), ('joaquin', 'PERSON'), ('joaquin choreography', 'ORG'), ('one', 'CARDINAL'), ('one', 'CARDINAL')]\n",
            "[('joaquín phoenix', 'ORG')]\n",
            "[('el critique', 'GPE'), ('alfred hitchcock', 'PERSON'), ('shell', 'ORG'), ('stellar', 'NORP'), ('joaquin', 'PERSON'), ('bruce wayne', 'PERSON'), ('murray franklincharacter development', 'PERSON'), ('seven', 'CARDINAL'), ('70', 'CARDINAL'), ('todd philip', 'PERSON'), ('thomas wayne', 'PERSON'), ('truman', 'PERSON'), ('american', 'NORP'), ('wtf', 'ORG'), ('five', 'CARDINAL'), ('one', 'CARDINAL'), ('thousand', 'CARDINAL'), ('shakespeare', 'PERSON')]\n",
            "[('arthur masterful de niro', 'PERSON'), ('nod jerry lewis', 'PERSON')]\n",
            "[('asinine script', 'PERSON'), ('one', 'CARDINAL'), ('zero', 'CARDINAL'), ('arthur', 'PERSON'), ('two', 'CARDINAL'), ('joker', 'GPE'), ('many year', 'DATE'), ('boon hollywood', 'PERSON'), ('second', 'ORDINAL'), ('one', 'CARDINAL')]\n",
            "[('joaquin phoenix amazing performance', 'PERSON'), ('foundation joker', 'ORG'), ('two', 'CARDINAL')]\n",
            "[]\n",
            "[('joker unique', 'PERSON'), ('day day', 'DATE')]\n",
            "[('joaquin phoenix', 'PERSON'), ('people decade', 'DATE')]\n",
            "[]\n",
            "[('hour', 'TIME'), ('guy oscar', 'PERSON')]\n",
            "[('kinda boringit', 'PERSON')]\n",
            "[('one', 'CARDINAL'), ('one', 'CARDINAL')]\n",
            "[('hour', 'TIME')]\n",
            "[('give least one', 'CARDINAL'), ('eleven', 'CARDINAL'), ('one', 'CARDINAL'), ('nolans', 'NORP'), ('arthur fleck', 'PERSON'), ('robert di', 'PERSON'), ('one', 'CARDINAL'), ('everyoneif', 'ORG'), ('phillipss joker depiction', 'ORG'), ('boil', 'ORG'), ('arthur', 'PERSON'), ('arthur', 'PERSON')]\n",
            "[('joaquin creativity', 'PERSON')]\n",
            "[('joaquin phoenix', 'PERSON'), ('arthur fleck', 'PERSON'), ('quotidian', 'NORP'), ('robert de niro', 'PERSON'), ('murray franklin', 'PERSON'), ('endoftheyear', 'ORG')]\n",
            "[('joaquin phoenix', 'PERSON'), ('god', 'PERSON'), ('war day', 'DATE'), ('arthur', 'PERSON'), ('arthur', 'PERSON'), ('arthur', 'PERSON'), ('gruesome joker', 'ORG'), ('arthur jokermixed', 'PERSON'), ('70', 'CARDINAL'), ('scorsese', 'NORP'), ('one', 'CARDINAL'), ('one', 'CARDINAL'), ('three', 'CARDINAL')]\n",
            "[]\n",
            "[]\n",
            "[('absolute disappointment', 'ORG'), ('hype', 'GPE'), ('phoenix', 'GPE')]\n",
            "[]\n",
            "[('evolves joker end joker', 'ORG'), ('joaquin', 'PERSON')]\n",
            "[('year', 'DATE')]\n",
            "[('one', 'CARDINAL'), ('maybephoenixs joker', 'ORG'), ('one', 'CARDINAL'), ('one', 'CARDINAL'), ('three', 'CARDINAL'), ('jack napier', 'PERSON'), ('first keaton', 'ORG'), ('phoenix', 'GPE'), ('first', 'ORDINAL'), ('one', 'CARDINAL'), ('second', 'ORDINAL'), ('tony rich', 'PERSON'), ('jerkand bruce wayne', 'PERSON'), ('batman joker', 'ORG'), ('year', 'DATE'), ('one', 'CARDINAL'), ('second', 'ORDINAL'), ('one', 'CARDINAL')]\n",
            "[('first', 'ORDINAL')]\n",
            "[('joaquin performance', 'PERSON')]\n",
            "[('scorsese', 'NORP'), ('one', 'CARDINAL'), ('dozen', 'CARDINAL'), ('arthur', 'PERSON'), ('portrayal joker', 'ORG'), ('arthur', 'PERSON'), ('thomas wayne character', 'PERSON'), ('first', 'ORDINAL'), ('two', 'CARDINAL'), ('two', 'CARDINAL'), ('one', 'CARDINAL'), ('one', 'CARDINAL'), ('decade later', 'DATE'), ('scorsese', 'NORP'), ('tim burton', 'PERSON'), ('today', 'DATE')]\n",
            "[('two', 'CARDINAL'), ('one', 'CARDINAL')]\n",
            "[]\n",
            "[('one', 'CARDINAL'), ('year', 'DATE')]\n",
            "[]\n",
            "[('one', 'CARDINAL')]\n",
            "[]\n",
            "[('joaquin phoenix', 'PERSON'), ('todd phillips', 'PERSON'), ('resistance incel', 'PERSON'), ('robert de niro', 'PERSON')]\n",
            "[('performance joaquin', 'PERSON'), ('mentaly ill', 'PERSON'), ('title arthur clown', 'ORG'), ('universe feld', 'PERSON')]\n",
            "[('new joker rivalry', 'ORG')]\n",
            "[('yesterday day', 'DATE'), ('mcdonalds', 'ORG')]\n",
            "[('arthur', 'PERSON'), ('murray franklin', 'PERSON'), ('arthur fleck cross murray', 'PERSON'), ('arthur mentally', 'ORG'), ('ill loner', 'PERSON'), ('trash murray call police', 'ORG'), ('arthur ill tell', 'ORG'), ('arthur', 'ORG'), ('murray head', 'PERSON'), ('three', 'CARDINAL'), ('joaquin phoenix', 'PERSON'), ('robert de niro', 'PERSON'), ('standup performance', 'PERSON'), ('de niro', 'PERSON'), ('endedup incredibly c h r c b u', 'FAC'), ('mark joaquin phoenix', 'PERSON')]\n",
            "[('one', 'CARDINAL')]\n",
            "[]\n",
            "[('joker masterpiece', 'ORG'), ('flawless board', 'ORG'), ('hollywood', 'GPE')]\n",
            "[]\n",
            "[('joaquin shoot', 'PERSON'), ('guy subway cowardice', 'PERSON'), ('joaquins joker', 'PERSON')]\n",
            "[('one', 'CARDINAL')]\n",
            "[('joaquin phoenix', 'PERSON'), ('christian', 'NORP'), ('robert de niro', 'PERSON')]\n",
            "[('half', 'CARDINAL'), ('last minute', 'TIME'), ('gore', 'PERSON')]\n",
            "[('two hour', 'TIME')]\n",
            "[('first', 'ORDINAL')]\n",
            "[]\n",
            "[('turkey', 'GPE'), ('le watch', 'ORG'), ('supervillians', 'NORP'), ('hung long', 'PERSON'), ('wheelsif', 'PERSON'), ('jack nicholson', 'PERSON')]\n",
            "[('one', 'CARDINAL'), ('year', 'DATE'), ('joaquin phoenix', 'PERSON'), ('mouth', 'PERSON'), ('half', 'CARDINAL'), ('first', 'ORDINAL'), ('one', 'CARDINAL')]\n",
            "[('one', 'CARDINAL'), ('one', 'CARDINAL'), ('arthur', 'PERSON')]\n",
            "[('s itjoaquin', 'PRODUCT'), ('phoenix', 'GPE')]\n",
            "[('year earlier', 'DATE')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWOtvT2rHNWy"
      },
      "source": [
        "**Write your explanations of the constituency parsing tree and dependency parsing tree here (Question 3-2):** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RytFpq2gjKqL"
      },
      "source": [
        "'''\n",
        "Write your explanations of the constituency parsing tree and dependency parsing tree here.\n",
        "\n",
        "\n",
        "**Dependency parsing** - displays grammatical structure where each word represents a node and followed by links to its dependents.\n",
        " It displays the relation between words.\n",
        "\n",
        "**Consituency parsing ** - displays syntactic structure where the words are organized into nested constituents.\n",
        "Both are helpful in word processing systems and grammar correction.\n"
      ]
    }
  ]
}