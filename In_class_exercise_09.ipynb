{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "In_class_exercise_09.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rushithakondreddy/haihua_INFO5731_Spring2020/blob/main/In_class_exercise_09.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2mYMHd_l0kt"
      },
      "source": [
        "# **The ninth in-class-exercise (20 points in total, 4/16/2021)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUJNMxl2l0ky"
      },
      "source": [
        "The purpose of the exercise is to practice different machine learning algorithms for text classification as well as the performance evaluation. In addition, you are requried to conduct *10 fold cross validation (https://scikit-learn.org/stable/modules/cross_validation.html)* in the training. \n",
        "\n",
        "The dataset can be download from here: https://github.com/unt-iialab/info5731_spring2021/blob/main/class_exercises/exercise09_datacollection.zip. The dataset contains two files train data and test data for sentiment analysis in IMDB review, it has two categories: 1 represents positive and 0 represents negative. You need to split the training data into training and validate data (80% for training and 20% for validation, https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6) and perform 10 fold cross validation while training the classifier. The final trained model was final evaluated on the test data. \n",
        "\n",
        "Algorithms:\n",
        "\n",
        "(1) MultinominalNB\n",
        "\n",
        "(2) SVM \n",
        "\n",
        "(3) KNN \n",
        "\n",
        "(4) Decision tree\n",
        "\n",
        "(5) Random Forest\n",
        "\n",
        "(6) XGBoost\n",
        "\n",
        "Evaluation measurement:\n",
        "\n",
        "(1) Accuracy\n",
        "\n",
        "(2) Recall\n",
        "\n",
        "(3) Precison \n",
        "\n",
        "(4) F-1 score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Yq6_Xa2l0k0"
      },
      "source": [
        "# Write your code here\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold\n",
        "from xgboost import XGBClassifier"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "WdNiSoC2nSIc",
        "outputId": "5dd4c119-ccae-4269-a28a-87a3a2e3c5ba"
      },
      "source": [
        "train_df = pd.read_csv(r'/content/stsa-train.txt',sep = 'delimiter=',header= None,names=['Text'])\n",
        "train_df[['Sentiment','Text']] = train_df[\"Text\"].str.split(\" \", 1, expand=True)\n",
        "test_df = pd.read_csv(r'/content/stsa-test.txt',sep = 'delimiter=',header= None,names=['Text'])\n",
        "test_df[['Sentiment','Text']] = test_df[\"Text\"].str.split(\" \", 1, expand=True)\n",
        "train_df.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a stirring , funny and finally transporting re...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>apparently reassembled from the cutting-room f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>they presume their audience wo n't sit still f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>this is a visually stunning rumination on love...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>jonathan parker 's bartleby should have been t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text Sentiment\n",
              "0  a stirring , funny and finally transporting re...         1\n",
              "1  apparently reassembled from the cutting-room f...         0\n",
              "2  they presume their audience wo n't sit still f...         0\n",
              "3  this is a visually stunning rumination on love...         1\n",
              "4  jonathan parker 's bartleby should have been t...         1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "_H7Du8-LnU8t",
        "outputId": "edfaba03-031d-4cc7-d26d-57d187750ad7"
      },
      "source": [
        "test_df.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>no movement , no yuks , not much of anything .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a gob of drivel so sickly sweet , even the eag...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gangs of new york is an unapologetic mess , wh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>we never really feel involved with the story ,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>this is one of polanski 's best films .</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text Sentiment\n",
              "0     no movement , no yuks , not much of anything .         0\n",
              "1  a gob of drivel so sickly sweet , even the eag...         0\n",
              "2  gangs of new york is an unapologetic mess , wh...         0\n",
              "3  we never really feel involved with the story ,...         0\n",
              "4            this is one of polanski 's best films .         1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jRlyMDLnXrY",
        "outputId": "2cff25ed-98e3-4636-fe2d-893f61d639b9"
      },
      "source": [
        "# Clean data\n",
        "import nltk\n",
        "import re\n",
        "import string\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "stopword=nltk.corpus.stopwords.words('english')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wl= WordNetLemmatizer()\n",
        "def clean_text(data):\n",
        "  data=\"\".join([word.lower() for word in data if word not in string.punctuation])\n",
        "  data = re.sub(\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\", \" \", data)\n",
        "  tokens = re.split('\\W+',data)\n",
        "  data = [wl.lemmatize(word) for word in tokens if word not in stopword]\n",
        "  return data"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIQZNHK9nb2c",
        "outputId": "7a9ce3d3-6463-48e5-d6a7-995049c480f8"
      },
      "source": [
        "# Convert text and train data into numerical\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf_vect = TfidfVectorizer(analyzer = clean_text)\n",
        "X_tfidf = tfidf_vect.fit_transform(train_df['Text'])\n",
        "print(X_tfidf.shape)\n",
        "X_tfidf_df=pd.DataFrame(X_tfidf.toarray())\n",
        "X_tfidf_df.columns=tfidf_vect.get_feature_names()\n",
        "X_test_tfidf = tfidf_vect.transform(test_df['Text'])\n",
        "print(X_test_tfidf.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6920, 13343)\n",
            "(1821, 13343)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZEhCM6nnfpl"
      },
      "source": [
        "#(1) MultinominalNB\n",
        "mnb = MultinomialNB()\n",
        "#(2) SVM\n",
        "svm = LinearSVC()\n",
        "#(3) KNN\n",
        "knn = KNeighborsClassifier(n_neighbors=5,n_jobs=-1)\n",
        "#(4) Decision tree\n",
        "dt = DecisionTreeClassifier()\n",
        "#(5) Random Forest\n",
        "rf = RandomForestClassifier()\n",
        "#(6) XGBoost\n",
        "xgb = XGBClassifier()\n",
        "\n",
        "#split the data\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_tfidf_df, train_df['Sentiment'].values,\n",
        "                                                test_size=0.2, random_state=42)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNPEFxUMnjF_",
        "outputId": "52507939-4ed1-442b-e580-c12a68bd0384"
      },
      "source": [
        "#(1) MultinominalNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "mnb_test = mnb.fit(x_train,y_train)\n",
        "y_mnb = mnb_test.predict(x_test)\n",
        "print('Accuracy Score %s' % accuracy_score(y_mnb,y_test))\n",
        "print(classification_report(y_test,y_mnb))\n",
        "from sklearn.model_selection import cross_val_score\n",
        "scores_MNB = cross_val_score(mnb, x_test, y_test, cv=10)\n",
        "print(\"Accuracy with MNB\",scores_MNB.mean())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score 0.7955202312138728\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.70      0.77       671\n",
            "           1       0.76      0.88      0.82       713\n",
            "\n",
            "    accuracy                           0.80      1384\n",
            "   macro avg       0.80      0.79      0.79      1384\n",
            "weighted avg       0.80      0.80      0.79      1384\n",
            "\n",
            "Accuracy with MNB 0.7247054530288813\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9KJUr21nlhz",
        "outputId": "4926bfef-cca8-4da9-c6ac-8c343d42e360"
      },
      "source": [
        "#(2) SVM\n",
        "svm_test = svm.fit(x_train,y_train)\n",
        "y_svm = svm_test.predict(x_test)\n",
        "print('Accuracy Score %s' % accuracy_score(y_svm,y_test))\n",
        "print(classification_report(y_test,y_svm))\n",
        "from sklearn.model_selection import cross_val_score\n",
        "scores_SVM = cross_val_score(svm, x_test, y_test, cv=10)\n",
        "print(\"Accuracy with SVM\",scores_SVM.mean())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score 0.791907514450867\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.75      0.78       671\n",
            "           1       0.78      0.83      0.80       713\n",
            "\n",
            "    accuracy                           0.79      1384\n",
            "   macro avg       0.79      0.79      0.79      1384\n",
            "weighted avg       0.79      0.79      0.79      1384\n",
            "\n",
            "Accuracy with SVM 0.7348034615785632\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8alrthVnnpN",
        "outputId": "2b02d634-eb87-473e-9f49-b6c29c22ff7c"
      },
      "source": [
        "#(3) KNN\n",
        "knn_test = knn.fit(x_train,y_train)\n",
        "y_knn = knn_test.predict(x_test)\n",
        "print('Accuracy Score %s' % accuracy_score(y_knn,y_test))\n",
        "print(classification_report(y_test,y_knn))\n",
        "from sklearn.model_selection import cross_val_score\n",
        "scores_KNN = cross_val_score(knn, x_test, y_test, cv=10)\n",
        "print(\"Accuracy with knn\",scores_KNN.mean())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score 0.7398843930635838\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.70      0.72       671\n",
            "           1       0.74      0.77      0.75       713\n",
            "\n",
            "    accuracy                           0.74      1384\n",
            "   macro avg       0.74      0.74      0.74      1384\n",
            "weighted avg       0.74      0.74      0.74      1384\n",
            "\n",
            "Accuracy with knn 0.6675737670732979\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZzuuMk9npwz",
        "outputId": "dd9814f1-1400-423b-a394-9b54dad9b97d"
      },
      "source": [
        "#(4) Decision tree\n",
        "des_tree_test = dt.fit(x_train,y_train)\n",
        "y_des_tree = des_tree_test.predict(x_test)\n",
        "print('Accuracy Score %s' % accuracy_score(y_des_tree,y_test))\n",
        "print(classification_report(y_test,y_des_tree))\n",
        "scores_DT = cross_val_score(dt, x_test, y_test, cv=10)\n",
        "print(\"Accuracy with Decision trees\",scores_DT.mean())\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score 0.6690751445086706\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.63      0.65       671\n",
            "           1       0.67      0.71      0.69       713\n",
            "\n",
            "    accuracy                           0.67      1384\n",
            "   macro avg       0.67      0.67      0.67      1384\n",
            "weighted avg       0.67      0.67      0.67      1384\n",
            "\n",
            "Accuracy with Decision trees 0.6090605776248565\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKLZhctunyj-",
        "outputId": "48810900-9d16-49c3-d00f-aefcd134ddb8"
      },
      "source": [
        "#(5) Random Forest\n",
        "rf_test = rf.fit(x_train,y_train)\n",
        "y_rf = rf_test.predict(x_test)\n",
        "print('Accuracy Score %s' % accuracy_score(y_rf,y_test))\n",
        "print(classification_report(y_test,y_rf))\n",
        "scores_RF = cross_val_score(rf, x_test, y_test, cv=10)\n",
        "print(\"Accuracy with Random Forest\",scores_RF.mean())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score 0.7384393063583815\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.63      0.70       671\n",
            "           1       0.71      0.84      0.77       713\n",
            "\n",
            "    accuracy                           0.74      1384\n",
            "   macro avg       0.75      0.74      0.73      1384\n",
            "weighted avg       0.75      0.74      0.74      1384\n",
            "\n",
            "Accuracy with Random Forest 0.6885569805025545\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-54lRTdBn1Oo",
        "outputId": "c9592e21-4508-4b1d-817c-6515d871467d"
      },
      "source": [
        "#(6) XGBoost\n",
        "xgb_test = xgb.fit(x_train,y_train)\n",
        "y_xgb = xgb_test.predict(x_test)\n",
        "print('Accuracy Score %s' % accuracy_score(y_xgb,y_test))\n",
        "print(classification_report(y_test,y_xgb))\n",
        "scores_XGB = cross_val_score(xgb, x_test, y_test, cv=10)\n",
        "print(\"Accuracy with XGBoost\",scores_XGB.mean())"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score 0.6445086705202312\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.40      0.52       671\n",
            "           1       0.61      0.88      0.72       713\n",
            "\n",
            "    accuracy                           0.64      1384\n",
            "   macro avg       0.68      0.64      0.62      1384\n",
            "weighted avg       0.68      0.64      0.62      1384\n",
            "\n",
            "Accuracy with XGBoost 0.6184704410384736\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbqNbqsXn3gq",
        "outputId": "ab05c78e-c172-4b2c-aec2-895fbe7fcac0"
      },
      "source": [
        "print(\"Accuracy with MNB\",scores_MNB.mean())\n",
        "print(\"Accuracy with SVM\",scores_SVM.mean())\n",
        "print(\"Accuracy with knn\",scores_KNN.mean())\n",
        "print(\"Accuracy with Decision trees\",scores_DT.mean())\n",
        "print(\"Accuracy with Random Forest\",scores_RF.mean())\n",
        "print(\"Accuracy with XGBoost\",scores_XGB.mean())"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy with MNB 0.7247054530288813\n",
            "Accuracy with SVM 0.7348034615785632\n",
            "Accuracy with knn 0.6675737670732979\n",
            "Accuracy with Decision trees 0.6090605776248565\n",
            "Accuracy with Random Forest 0.6885569805025545\n",
            "Accuracy with XGBoost 0.6184704410384736\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOOeZhVAn6Pi",
        "outputId": "9ea72fb4-8945-4f2c-b411-390f5a18e698"
      },
      "source": [
        "predict_mnb = mnb_test.predict(X_test_tfidf)\n",
        "print('Final trained model(MNB) with high accuracy evaluated on the test data: %s' % accuracy_score(predict_mnb,test_df['Sentiment']))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final trained model(MNB) with high accuracy evaluated on the test data: 0.7946183415705657\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}